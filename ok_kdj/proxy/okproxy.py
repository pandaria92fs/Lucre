import pandas as pd
import asyncio
import aiohttp
import time
from datetime import datetime, timedelta
import json
import os
from typing import List, Dict, Any


class OKXKlineFetcher:
    def __init__(self):
        self.base_url = "https://www.okx.com"
        self.kline_endpoint = "/api/v5/market/candles"

        # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        # é¡¹ç›®æ ¹ç›®å½•
        self.project_root = os.path.dirname(self.script_dir)

        # å¹¶å‘æ§åˆ¶å‚æ•°
        self.max_concurrent = 5  # æœ€å¤§å¹¶å‘æ•°
        self.rate_limit = 5  # æ¯ç§’è¯·æ±‚æ•°
        self.semaphore = None  # ä¿¡å·é‡ï¼Œç”¨äºæ§åˆ¶å¹¶å‘æ•°

    def read_swap_csv(self, csv_path=None):
        """
        è¯»å–swap.csvæ–‡ä»¶è·å–instIdåˆ—è¡¨

        Args:
            csv_path (str): CSVæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„

        Returns:
            list: instIdåˆ—è¡¨
        """
        if csv_path is None:
            # é»˜è®¤è·¯å¾„ï¼šscript/sqqq/swap.csv
            csv_path = os.path.join(self.script_dir, "swap.csv")

        # å¦‚æœä¼ å…¥çš„æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œåˆ™ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
        if not os.path.isabs(csv_path):
            csv_path = os.path.join(self.project_root, csv_path)

        try:
            if not os.path.exists(csv_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
                return []

            df = pd.read_csv(csv_path)
            inst_ids = df['instId'].tolist()
            print(f"ğŸ“Š ä» {csv_path} è¯»å–åˆ° {len(inst_ids)} ä¸ªäº¤æ˜“å¯¹")
            return inst_ids
        except Exception as e:
            print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}")
            return []

    async def get_kline_data_async(self, session: aiohttp.ClientSession, inst_id: str, bar: str = "1H", limit: int = 9):
        """
        å¼‚æ­¥è·å–æŒ‡å®šäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®

        Args:
            session (aiohttp.ClientSession): HTTPä¼šè¯
            inst_id (str): äº¤æ˜“å¯¹IDï¼Œå¦‚ "BTC-USDT-SWAP"
            bar (str): Kçº¿å‘¨æœŸï¼Œ1m/3m/5m/15m/30m/1H/2H/4H/6H/12H/1D/1W/1M/3M/6M/1Y
            limit (int): è·å–çš„Kçº¿æ•°é‡ï¼Œé»˜è®¤9æ ¹ï¼ˆ9å°æ—¶ï¼‰

        Returns:
            dict: Kçº¿æ•°æ®
        """
        url = f"{self.base_url}{self.kline_endpoint}"
        params = {
            'instId': inst_id,
            'bar': bar,
            'limit': str(limit)
        }

        async with self.semaphore:  # é™åˆ¶å¹¶å‘æ•°
            try:
                async with session.get(url, params=params, timeout=10) as response:
                    response.raise_for_status()
                    data = await response.json()

                    if data.get('code') == '0':
                        return {
                            'instId': inst_id,
                            'success': True,
                            'data': data.get('data', []),
                            'count': len(data.get('data', []))
                        }
                    else:
                        return {
                            'instId': inst_id,
                            'success': False,
                            'error': data.get('msg', 'æœªçŸ¥é”™è¯¯'),
                            'data': []
                        }

            except Exception as e:
                return {
                    'instId': inst_id,
                    'success': False,
                    'error': f'è¯·æ±‚å¤±è´¥: {str(e)}',
                    'data': []
                }

    def get_kline_data(self, inst_id, bar="1H", limit=9):
        """
        åŒæ­¥è·å–æŒ‡å®šäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰

        Args:
            inst_id (str): äº¤æ˜“å¯¹IDï¼Œå¦‚ "BTC-USDT-SWAP"
            bar (str): Kçº¿å‘¨æœŸï¼Œ1m/3m/5m/15m/30m/1H/2H/4H/6H/12H/1D/1W/1M/3M/6M/1Y
            limit (int): è·å–çš„Kçº¿æ•°é‡ï¼Œé»˜è®¤9æ ¹ï¼ˆ9å°æ—¶ï¼‰

        Returns:
            dict: Kçº¿æ•°æ®
        """
        import requests

        url = f"{self.base_url}{self.kline_endpoint}"
        params = {
            'instId': inst_id,
            'bar': bar,
            'limit': str(limit)
        }

        try:
            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()

            data = response.json()

            if data.get('code') == '0':
                return {
                    'instId': inst_id,
                    'success': True,
                    'data': data.get('data', []),
                    'count': len(data.get('data', []))
                }
            else:
                return {
                    'instId': inst_id,
                    'success': False,
                    'error': data.get('msg', 'æœªçŸ¥é”™è¯¯'),
                    'data': []
                }

        except Exception as e:
            return {
                'instId': inst_id,
                'success': False,
                'error': f'è¯·æ±‚å¤±è´¥: {str(e)}',
                'data': []
            }

    async def process_batch(self, session: aiohttp.ClientSession, batch: List[str], bar: str, limit: int):
        """
        å¤„ç†ä¸€æ‰¹äº¤æ˜“å¯¹çš„Kçº¿æ•°æ®è·å–

        Args:
            session: HTTPä¼šè¯
            batch: äº¤æ˜“å¯¹IDåˆ—è¡¨
            bar: Kçº¿å‘¨æœŸ
            limit: Kçº¿æ•°é‡

        Returns:
            dict: æ‰¹æ¬¡å¤„ç†ç»“æœ
        """
        tasks = []
        for inst_id in batch:
            task = self.get_kline_data_async(session, inst_id, bar, limit)
            tasks.append(task)

        # å¹¶å‘æ‰§è¡Œå½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)

        batch_results = {}
        for result in results:
            if isinstance(result, dict):
                batch_results[result['instId']] = result
            else:
                # å¤„ç†å¼‚å¸¸æƒ…å†µ
                print(f"âŒ æ‰¹æ¬¡å¤„ç†å¼‚å¸¸: {result}")

        return batch_results

    async def fetch_all_klines_async(self, csv_path=None, bar="1H", limit=9):
        """
        å¼‚æ­¥æ‰¹é‡è·å–æ‰€æœ‰äº¤æ˜“å¯¹çš„Kçº¿æ•°æ®ï¼Œæ§åˆ¶å¹¶å‘æ•°ä¸ºæ¯ç§’5ä¸ª

        Args:
            csv_path (str): CSVæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            bar (str): Kçº¿å‘¨æœŸ
            limit (int): æ¯ä¸ªäº¤æ˜“å¯¹è·å–çš„Kçº¿æ•°é‡

        Returns:
            dict: æ‰€æœ‰Kçº¿æ•°æ®ç»“æœ
        """
        inst_ids = self.read_swap_csv(csv_path)
        if not inst_ids:
            return {}

        # åˆå§‹åŒ–ä¿¡å·é‡ï¼Œæ§åˆ¶æœ€å¤§å¹¶å‘æ•°
        self.semaphore = asyncio.Semaphore(self.max_concurrent)

        results = {}
        success_count = 0
        failed_count = 0

        print(f"ğŸš€ å¼€å§‹å¼‚æ­¥è·å– {len(inst_ids)} ä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®...")
        print(f"ğŸ“Š å‚æ•°: å‘¨æœŸ={bar}, æ•°é‡={limit}æ ¹, å¹¶å‘={self.max_concurrent}, é™é€Ÿ={self.rate_limit}/ç§’")

        # åˆ›å»ºæ‰¹æ¬¡ï¼Œæ¯æ‰¹5ä¸ªï¼ˆæ¯ç§’å¤„ç†5ä¸ªï¼‰
        batch_size = self.rate_limit
        batches = [inst_ids[i:i + batch_size] for i in range(0, len(inst_ids), batch_size)]

        start_time = time.time()

        async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30),
                connector=aiohttp.TCPConnector(limit=self.max_concurrent)
        ) as session:

            for batch_idx, batch in enumerate(batches, 1):
                batch_start_time = time.time()

                print(f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡ [{batch_idx}/{len(batches)}] - {len(batch)} ä¸ªäº¤æ˜“å¯¹")

                # å¤„ç†å½“å‰æ‰¹æ¬¡
                batch_results = await self.process_batch(session, batch, bar, limit)
                results.update(batch_results)

                # ç»Ÿè®¡ç»“æœ
                for inst_id, result in batch_results.items():
                    if result['success']:
                        success_count += 1
                        print(f"âœ… {inst_id}: è·å– {result['count']} æ ¹Kçº¿")
                    else:
                        failed_count += 1
                        print(f"âŒ {inst_id}: {result['error']}")

                batch_end_time = time.time()
                batch_duration = batch_end_time - batch_start_time

                # å¦‚æœè¿™ä¸æ˜¯æœ€åä¸€æ‰¹ï¼Œä¸”å¤„ç†æ—¶é—´å°äº1ç§’ï¼Œåˆ™ç­‰å¾…
                if batch_idx < len(batches) and batch_duration < 1.0:
                    sleep_time = 1.0 - batch_duration
                    print(f"â±ï¸  æ‰¹æ¬¡å®Œæˆç”¨æ—¶ {batch_duration:.2f}sï¼Œç­‰å¾… {sleep_time:.2f}s...")
                    await asyncio.sleep(sleep_time)

        total_time = time.time() - start_time
        print(f"\nğŸ“Š å¼‚æ­¥æ‰¹é‡è·å–å®Œæˆ (ç”¨æ—¶ {total_time:.2f}s):")
        print(f"   âœ… æˆåŠŸ: {success_count} ä¸ª")
        print(f"   âŒ å¤±è´¥: {failed_count} ä¸ª")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {success_count / (success_count + failed_count) * 100:.1f}%")
        print(f"   âš¡ å¹³å‡é€Ÿåº¦: {len(inst_ids) / total_time:.2f} ä¸ª/ç§’")

        return results

    def fetch_all_klines(self, csv_path=None, bar="1H", limit=9, delay=0.1, use_async=True):
        """
        æ‰¹é‡è·å–æ‰€æœ‰äº¤æ˜“å¯¹çš„Kçº¿æ•°æ®

        Args:
            csv_path (str): CSVæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            bar (str): Kçº¿å‘¨æœŸ
            limit (int): æ¯ä¸ªäº¤æ˜“å¯¹è·å–çš„Kçº¿æ•°é‡
            delay (float): åŒæ­¥æ¨¡å¼ä¸‹çš„è¯·æ±‚é—´éš”
            use_async (bool): æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼Œé»˜è®¤True

        Returns:
            dict: æ‰€æœ‰Kçº¿æ•°æ®ç»“æœ
        """
        if use_async:
            # ä½¿ç”¨å¼‚æ­¥æ¨¡å¼
            return asyncio.run(self.fetch_all_klines_async(csv_path, bar, limit))
        else:
            # ä½¿ç”¨åŒæ­¥æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            return self._fetch_all_klines_sync(csv_path, bar, limit, delay)

    def _fetch_all_klines_sync(self, csv_path=None, bar="1H", limit=9, delay=0.1):
        """
        åŒæ­¥æ¨¡å¼æ‰¹é‡è·å–ï¼ˆåŸæœ‰é€»è¾‘ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
        """
        inst_ids = self.read_swap_csv(csv_path)
        if not inst_ids:
            return {}

        results = {}
        success_count = 0
        failed_count = 0

        print(f"ğŸš€ å¼€å§‹åŒæ­¥è·å– {len(inst_ids)} ä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®...")
        print(f"ğŸ“Š å‚æ•°: å‘¨æœŸ={bar}, æ•°é‡={limit}æ ¹, å»¶è¿Ÿ={delay}ç§’")

        for i, inst_id in enumerate(inst_ids, 1):
            print(f"ğŸ“ˆ [{i}/{len(inst_ids)}] è·å– {inst_id} çš„Kçº¿æ•°æ®...")

            result = self.get_kline_data(inst_id, bar, limit)
            results[inst_id] = result

            if result['success']:
                success_count += 1
                print(f"âœ… æˆåŠŸè·å– {result['count']} æ ¹Kçº¿")
            else:
                failed_count += 1
                print(f"âŒ è·å–å¤±è´¥: {result['error']}")

            # é¿å…è¯·æ±‚é¢‘ç‡è¿‡å¿«
            if delay > 0:
                time.sleep(delay)

        print(f"\nğŸ“Š åŒæ­¥æ‰¹é‡è·å–å®Œæˆ:")
        print(f"   âœ… æˆåŠŸ: {success_count} ä¸ª")
        print(f"   âŒ å¤±è´¥: {failed_count} ä¸ª")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {success_count / (success_count + failed_count) * 100:.1f}%")

        return results

    def format_kline_data(self, kline_result):
        """
        æ ¼å¼åŒ–Kçº¿æ•°æ®ä¸ºæ˜“è¯»æ ¼å¼

        Args:
            kline_result (dict): get_kline_dataè¿”å›çš„ç»“æœ

        Returns:
            list: æ ¼å¼åŒ–åçš„Kçº¿æ•°æ®
        """
        if not kline_result['success'] or not kline_result['data']:
            return []

        formatted_data = []
        for kline in kline_result['data']:
            # OKX Kçº¿æ•°æ®æ ¼å¼: [ts, o, h, l, c, vol, volCcy, volCcyQuote, confirm]
            formatted_data.append({
                'timestamp': kline[0],
                'datetime': datetime.fromtimestamp(int(kline[0]) / 1000).strftime('%Y-%m-%d %H:%M:%S'),
                'open': float(kline[1]),
                'high': float(kline[2]),
                'low': float(kline[3]),
                'close': float(kline[4]),
                'volume': float(kline[5]),
                'volume_currency': float(kline[6]),
                'volume_quote': float(kline[7]),
                'confirmed': kline[8] == '1'
            })

        return formatted_data

    def save_klines_to_csv(self, kline_results, output_dir=None):
        """
        å°†Kçº¿æ•°æ®ä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼ŒæŒ‰äº¤æ˜“å¯¹åˆ†æ–‡ä»¶å¤¹å­˜å‚¨
        ç»“æ„: kline_data_folder/äº¤æ˜“å¯¹åç§°/æ—¶é—´æˆ³.csv

        Args:
            kline_results (dict): fetch_all_klinesè¿”å›çš„ç»“æœ
            output_dir (str): è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤çš„kline_data_folderè·¯å¾„
        """
        if output_dir is None:
            # é»˜è®¤è¾“å‡ºåˆ° service/kline_data_folder/
            output_dir = os.path.join(self.project_root, "service", "kline_data_folder")

        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œåˆ™ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
        if not os.path.isabs(output_dir):
            output_dir = os.path.join(self.project_root, output_dir)

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"ğŸ“ åˆ›å»ºæ ¹ç›®å½•: {output_dir}")

        saved_count = 0
        timestamp = datetime.now().strftime("%Y%m%d_%H")

        for inst_id, result in kline_results.items():
            if result['success'] and result['data']:
                formatted_data = self.format_kline_data(result)
                if formatted_data:
                    df = pd.DataFrame(formatted_data)

                    # å¤„ç†äº¤æ˜“å¯¹åç§°ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦ä½œä¸ºæ–‡ä»¶å¤¹å
                    trading_pair = inst_id.replace('-USDT-SWAP', '').replace('-', '').replace('/', '')

                    # ä¸ºæ¯ä¸ªäº¤æ˜“å¯¹åˆ›å»ºå­æ–‡ä»¶å¤¹
                    pair_folder = os.path.join(output_dir, trading_pair)
                    if not os.path.exists(pair_folder):
                        os.makedirs(pair_folder)
                        print(f"ğŸ“ åˆ›å»ºäº¤æ˜“å¯¹ç›®å½•: {trading_pair}")

                    # æ–‡ä»¶åï¼šæ—¶é—´æˆ³.csv
                    csv_filename = f"{timestamp}.csv"
                    csv_path = os.path.join(pair_folder, csv_filename)

                    df.to_csv(csv_path, index=False, encoding='utf-8')
                    saved_count += 1
                    print(f"ğŸ’¾ å·²ä¿å­˜: {os.path.relpath(csv_path, self.project_root)}")

        print(f"\nğŸ“ å…±ä¿å­˜ {saved_count} ä¸ªKçº¿æ•°æ®æ–‡ä»¶åˆ° {os.path.relpath(output_dir, self.project_root)} ç›®å½•")


# ä½¿ç”¨ç¤ºä¾‹
def main():
    """
    ä¸»å‡½æ•° - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨OKXKlineFetcher
    """
    fetcher = OKXKlineFetcher()

    print("\n" + "=" * 50)
    print("ğŸš€ å¹¶å‘æ‰¹é‡è·å–Kçº¿æ•°æ® (æ¯ç§’5ä¸ª)")
    print("=" * 50)

    # ä½¿ç”¨å¼‚æ­¥å¹¶å‘æ¨¡å¼
    results = fetcher.fetch_all_klines(bar="1H", limit=30, use_async=True)

    if results:
        # ä¿å­˜åˆ°é»˜è®¤è·¯å¾„
        fetcher.save_klines_to_csv(results)

    # å¦‚æœéœ€è¦ä½¿ç”¨åŒæ­¥æ¨¡å¼ï¼Œå¯ä»¥è¿™æ ·è°ƒç”¨ï¼š
    # results = fetcher.fetch_all_klines(bar="1H", limit=30, use_async=False, delay=0.2)


# å¦‚æœè¦åœ¨proxyç›®å½•ä¸‹çš„okproxy.pyä¸­ä½¿ç”¨ï¼Œå¯ä»¥è¿™æ ·è°ƒç”¨ï¼š
def run_kline_fetcher():
    """
    åœ¨okproxy.pyä¸­è°ƒç”¨çš„ç®€åŒ–å‡½æ•°ï¼Œä½¿ç”¨å¹¶å‘æ¨¡å¼
    """
    fetcher = OKXKlineFetcher()

    print("ğŸš€ å¼€å§‹å¹¶å‘è·å–Kçº¿æ•°æ®...")

    # ä½¿ç”¨å¼‚æ­¥å¹¶å‘æ¨¡å¼ï¼Œæ¯ç§’5ä¸ªè¯·æ±‚
    results = fetcher.fetch_all_klines(bar="1H", limit=30, use_async=True)

    if results:
        fetcher.save_klines_to_csv(results)
        print("âœ… Kçº¿æ•°æ®è·å–å®Œæˆ!")
    else:
        print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•Kçº¿æ•°æ®")

    return results


if __name__ == "__main__":
    main()